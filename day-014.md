## tokenizer line issue recall
+ BBPE tokenizer의 메모리 이슈는 chunk 수가 아니었음

## issue recall
+ [day-012](https://github.com/hyoungseok/TIL/blob/master/day-012.md)에서 파악한 이슈 원인이 아니었음
+ 한 line에 전체 코퍼스를 넣어주는 것이 default라고 한 것은 사실이 아님
+ 기본적으로 하나의 documnet가 하나의 line을 쓰는 것이 맞음
+ 다만, 전체 document가 device 메모리 용량을 초과하는 경우에 에러가 발생
+ 즉, 여려 document를 한 line에 넣어도, 전체 document 용량이 device 메모리를 초과하면 에러는 마찬가지로 발생함

## solution
+ 일단, device 메모리를 파악함
```bash
$ free -h
```
+ 가용 메모리 용량으로 전체 코퍼스를 sampling 함
+ sampled corpus로 BBPE tokenizers를 구동함
